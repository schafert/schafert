+++
title = "Bayesian Inverse Reinforcement Learning for Collective Animal Movement"
date = "2022-01-01"
authors = ["Toryn L. J. Schafer", "Christopher K. Wikle", "Mevin B. Hooten"]
publication_types = ["2"]
publication = "The Annals of Applied Statistics, (16), _pp. 999 -- 1013_, https://doi.org/10.1214/21-AOAS1529"
publication_short = "The Annals of Applied Statistics, (16), _pp. 999 -- 1013_, https://doi.org/10.1214/21-AOAS1529"
abstract = "Agent-based methods allow for defining simple rules that generate complex group behaviors. The governing rules of such models are typically set *a priori* and parameters are tuned from observed behavior trajectories. Instead of making simplifying assumptions across all anticipated scenarios, inverse reinforcement learning provides inference on the short-term (local) rules governing long term behavior policies by using properties of a Markov decision process. We use the computationally efficient linearly-solvable Markov decision process to learn the local rules governing collective movement for a simulation of the self propelled-particle (SPP) model and a data application for a captive guppy population. The estimation of the behavioral decision costs is done in a Bayesian framework with basis function smoothing. We recover the true costs in the SPP simulation and find the guppies value collective movement more than targeted movement toward shelter."
abstract_short = ""
image_preview = ""
selected = false
projects = []
tags = []
url_pdf = "https://doi.org/10.1214/21-AOAS1529"
url_preprint = "https://arxiv.org/pdf/2009.04003.pdf"
url_code = ""
url_dataset = ""
url_project = ""
url_slides = ""
url_video = ""
url_poster = ""
url_source = ""
math = true
highlight = true
[header]
image = ""
caption = ""
+++
